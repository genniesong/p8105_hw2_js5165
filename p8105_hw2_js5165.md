p8105\_hw2\_js5165
================
Jingqi Song
September 26, 2018

Problem 1
---------

Import NYC transit data

``` r
p1_nyc = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")%>%
  janitor::clean_names()%>%
  gather(key = route_no, value=route_name,route1:route11)%>%
  separate(route_no, into = c("x", "route_number"), sep = 5) %>%
  filter(!is.na(route_name))%>%
  select(line, station_name, station_latitude, station_longitude, route_number,route_name, entry, vending, entrance_type, ada)%>%
  mutate(entry=ifelse(entry=='YES',yes=TRUE,no=FALSE))%>%
  arrange(line,station_name)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_integer(),
    ##   Route9 = col_integer(),
    ##   Route10 = col_integer(),
    ##   Route11 = col_integer(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

The dataset variables contain line, name of station, the latitude and longtitude of station; the number and name of route; whether the station allows entrance and entrance type; whether the station has vending and ADA compliance.

Cleaning steps: I first cleaned up variable names after importing data and used gather function to transpose. Then I separated the single route number from the variable that the observations contain the word "route", and omitted observations without information of route number. After selecting the variables we need, I arranged the dataset by line and station name. It is now a 4270 by 10 tidy dataset.

``` r
distinct_station = nrow(distinct(p1_nyc,station_name,line,.keep_all = TRUE))

ada_compliance = p1_nyc %>% 
  filter(ada == TRUE) %>% 
  distinct(station_name,line)
nrow(ada_compliance)
```

    ## [1] 84

``` r
allow_entrance = p1_nyc %>% 
  filter(entry==TRUE & vending == 'NO') %>% 
  distinct(line,station_name)
vending = p1_nyc %>% 
  filter(vending == 'NO') %>% 
  distinct(line,station_name)
proportion = nrow(allow_entrance)/nrow(vending)
proportion
```

    ## [1] 0.4343434

There are 465 distinct stations; 84 stations are ADA compliant; 43.43% of station entrances / exits without vending allow entrance.

``` r
a_train = p1_nyc %>% 
  filter(route_name=='A') %>% 
  distinct(station_name,line)
nrow(a_train)
```

    ## [1] 60

``` r
a_ada = p1_nyc %>% 
  filter(route_name=='A' & ada==TRUE) %>% 
  distinct(station_name,line)
nrow(a_ada)
```

    ## [1] 17

60 distinct stations serve the A train; of the stations that serve the A train, 17 are ADA compliant.

Problem 2
---------

``` r
p2_trash = read_excel(path = './data/HealthyHarborWaterWheelTotals2018-7-28.xlsx',sheet = 'Mr. Trash Wheel',range = cell_cols("A:N"))%>%
  janitor::clean_names()%>%
  filter(!is.na(date))%>%
  mutate(sports_balls=as.integer(signif(sports_balls)))
```

``` r
p2_2016 = read_excel(path = './data/HealthyHarborWaterWheelTotals2018-7-28.xlsx',sheet = '2016 Precipitation',range = cell_rows(2:14))%>%
  janitor::clean_names()%>%
  mutate(year=2016)

p2_2017 = read_excel(path = './data/HealthyHarborWaterWheelTotals2018-7-28.xlsx',sheet = '2017 Precipitation',range = cell_rows(2:14))%>%
  janitor::clean_names()%>%
  mutate(year=2017)

p2_1617=bind_rows(p2_2016,p2_2017)%>%
  janitor::clean_names()%>%
  select(year, everything())%>%
  mutate(month=month.name[month])
```

The dataset Mr. Trash Wheel has 285 observations, the key variable is weight\_tons. The dataset for year 2016-2017 precipitation has 24 observations; the key variable is total precipitation for each month. The total precipitation in 2017 is 32.93; the median number of sports balls in a dumpster in 2016 is 26.

Problem 3
---------

``` r
devtools::install_github("p8105/p8105.datasets")
```

    ## Skipping install of 'p8105.datasets' from a github remote, the SHA1 (21f5ad1c) has not changed since last install.
    ##   Use `force = TRUE` to force installation

``` r
library(p8105.datasets)

p3_brfsm=brfss_smart2010 %>% 
  janitor::clean_names() %>%
  separate(locationdesc, into = c("state", "county"), sep = " - ") %>%
  filter(topic=='Overall Health')%>%
  select(-class,-topic,-question,-sample_size,-locationabbr,-(confidence_limit_low:geo_location))%>%
  spread(key = response, value = data_value)%>%
  janitor::clean_names()%>%
  select(year,state,county,excellent,very_good,good,fair,poor)%>%
  mutate(above_good=excellent+very_good)
```

``` r
nrow(distinct(p3_brfsm,state,county))
```

    ## [1] 404

``` r
nrow(distinct(p3_brfsm,state))
```

    ## [1] 51

``` r
count(p3_brfsm,state)%>%
  arrange(-n)%>%
  head(1)
```

    ## # A tibble: 1 x 2
    ##   state     n
    ##   <chr> <int>
    ## 1 NJ      146

``` r
p3_brfsm%>%
  filter(year==2002, !is.na(excellent)) %>% 
  pull(excellent) %>% 
  median()
```

    ## [1] 23.6

``` r
p3_brfsm%>%
  filter(year==2002)%>%
  ggplot(aes(x = excellent))+ 
  geom_histogram()+
  labs(
    title = '"Excellent" response values in 2002',
    x = 'Proportion of "Excellent"'
  )
```

    ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.

    ## Warning: Removed 2 rows containing non-finite values (stat_bin).

![](p8105_hw2_js5165_files/figure-markdown_github/p3.2-1.png)

``` r
p3_brfsm%>%
  filter(county =='New York County' | county == 'Queens County')%>%
  ggplot(aes(x = year, y = excellent))+ 
  geom_point(aes(color = county))+
  labs(
    title = '“Excellent” response in 2 counties',
    x = 'Proportion of "Excellent"'
  )
```

![](p8105_hw2_js5165_files/figure-markdown_github/p3.2-2.png)

404 unique locations are included in the dataset; All states are represented; NJ is the state observed the most (146) In 2002, the median of the “Excellent” response value is 23.6.
